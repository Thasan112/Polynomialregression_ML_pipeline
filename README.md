# Polynomialregression_ML_pipeline
This project demonstrates how **Linear Regression** can underfit nonlinear data and how **Polynomial Regression** can improve the fit.   A synthetic quadratic dataset is generated, and different regression models are compared using **RÂ² score** and visualizations.

## ðŸ“Š Features
- Generate synthetic quadratic dataset with noise
- Fit **Linear Regression** model
- Fit **Polynomial Regression** (degree 2 and degree 3)
- Compare model performance using **RÂ² score**
- Visualize predictions vs. true data



ðŸ§° Dependencies

numpy

pandas

matplotlib

seaborn

scikit-learn

Google Colab


ðŸ“ˆ Results

Linear Regression: RÂ² â‰ˆ 0.58 â†’ underfits nonlinear data

Polynomial Regression (degree 2): RÂ² â‰ˆ 0.80 â†’ good fit

Polynomial Regression (degree 3): RÂ² â‰ˆ 0.79 â†’ slightly worse due to overfitting noise

Visualization shows how polynomial regression better captures the quadratic relationship.
