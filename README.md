# Polynomialregression_ML_pipeline
This project demonstrates how **Linear Regression** can underfit nonlinear data and how **Polynomial Regression** can improve the fit.   A synthetic quadratic dataset is generated, and different regression models are compared using **RÂ² score** and visualizations.

## ðŸ“Š Features
- Generate synthetic quadratic dataset with noise
- Fit **Linear Regression** model
- Fit **Polynomial Regression** (degree 2 and degree 3)
- Compare model performance using **RÂ² score**
- Visualize predictions vs. true data

ðŸ“ˆ Results

Linear Regression: RÂ² â‰ˆ 0.58 â†’ underfits nonlinear data

Polynomial Regression (degree 2): RÂ² â‰ˆ 0.80 â†’ good fit

Polynomial Regression (degree 3): RÂ² â‰ˆ 0.79 â†’ slightly worse due to overfitting noise

Visualization shows how polynomial regression better captures the quadratic relationship.

ðŸ§° Dependencies

numpy

pandas

matplotlib

seaborn

scikit-learn

Google Colab



polynomial-regression-demo/
â”‚â”€â”€ data/                         # (optional) dataset or generated data
â”‚â”€â”€ notebooks/
â”‚   â””â”€â”€ polynomial_regression.ipynb   # main notebook
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ data_generation.py        # dataset generation
â”‚   â”œâ”€â”€ linear_regression.py      # linear regression model
â”‚   â”œâ”€â”€ polynomial_regression.py  # polynomial regression model
â”‚   â””â”€â”€ visualization.py          # plotting utilities
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore
